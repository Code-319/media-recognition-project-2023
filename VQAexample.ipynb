{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.cloud.aliyuncs.com/pypi/simple/\n",
      "Requirement already satisfied: ultralytics in ./mcenv/lib/python3.9/site-packages (8.0.218)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in ./mcenv/lib/python3.9/site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in ./mcenv/lib/python3.9/site-packages (from ultralytics) (3.8.2)\n",
      "Requirement already satisfied: torch>=1.8.0 in ./mcenv/lib/python3.9/site-packages (from ultralytics) (2.1.1+cpu)\n",
      "Requirement already satisfied: numpy>=1.22.2 in ./mcenv/lib/python3.9/site-packages (from ultralytics) (1.24.1)\n",
      "Requirement already satisfied: psutil in ./mcenv/lib/python3.9/site-packages (from ultralytics) (5.9.6)\n",
      "Requirement already satisfied: thop>=0.1.1 in ./mcenv/lib/python3.9/site-packages (from ultralytics) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in ./mcenv/lib/python3.9/site-packages (from ultralytics) (0.16.1+cpu)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in ./mcenv/lib/python3.9/site-packages (from ultralytics) (4.8.1.78)\n",
      "Requirement already satisfied: scipy>=1.4.1 in ./mcenv/lib/python3.9/site-packages (from ultralytics) (1.11.4)\n",
      "Requirement already satisfied: pandas>=1.1.4 in ./mcenv/lib/python3.9/site-packages (from ultralytics) (2.1.3)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in ./mcenv/lib/python3.9/site-packages (from ultralytics) (4.66.1)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in ./mcenv/lib/python3.9/site-packages (from ultralytics) (0.13.0)\n",
      "Requirement already satisfied: py-cpuinfo in ./mcenv/lib/python3.9/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pillow>=7.1.2 in ./mcenv/lib/python3.9/site-packages (from ultralytics) (9.3.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in ./mcenv/lib/python3.9/site-packages (from ultralytics) (2.28.1)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in ./mcenv/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (6.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./mcenv/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./mcenv/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (4.45.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./mcenv/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./mcenv/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./mcenv/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./mcenv/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./mcenv/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./mcenv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib>=3.3.0->ultralytics) (3.17.0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./mcenv/lib/python3.9/site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./mcenv/lib/python3.9/site-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in ./mcenv/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in ./mcenv/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./mcenv/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./mcenv/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./mcenv/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (1.26.13)\n",
      "Requirement already satisfied: typing-extensions in ./mcenv/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (4.4.0)\n",
      "Requirement already satisfied: sympy in ./mcenv/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
      "Requirement already satisfied: networkx in ./mcenv/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (3.0)\n",
      "Requirement already satisfied: fsspec in ./mcenv/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (2023.4.0)\n",
      "Requirement already satisfied: jinja2 in ./mcenv/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: filelock in ./mcenv/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (3.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./mcenv/lib/python3.9/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./mcenv/lib/python3.9/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: http://mirrors.cloud.aliyuncs.com/pypi/simple/\n",
      "Collecting git+https://github.com/openai/CLIP.git\n",
      "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-i19lzfp0\n",
      "  Running command git clone -q https://github.com/openai/CLIP.git /tmp/pip-req-build-i19lzfp0\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ultralytics\n",
    "%pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import clip\n",
    "import torch\n",
    "yolov8 = YOLO(\"yolov8m-oiv7.pt\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "sample_img = Image.open(\"hand_pen.jpg\")\n",
    "clip_img = preprocess(sample_img).unsqueeze(0).to(device)\n",
    "question = \"What is in the hand?\"\n",
    "candidates = [\"a pen\", \"an apple\", \"a handgun\", \"a phone\", \"a computer\", \"a cattle\", \"a cake\"]\n",
    "input_texts = [f\"{question} {candidate}\" for candidate in candidates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    image_features = model.encode_image(clip_img)\n",
    "    qa_features = model.encode_text(clip.tokenize(input_texts).to(device))\n",
    "    similarity = (100.0 * image_features @ qa_features.T).softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_index = similarity.squeeze().argmax().item()\n",
    "best_answer = candidates[best_index]\n",
    "\n",
    "print(f\"{question}\\n{best_answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VQA(img_path: str, question: str, answers: list):\n",
    "  sample_img = Image.open(img_path)\n",
    "  clip_img = preprocess(sample_img).unsqueeze(0).to(device)\n",
    "  input_texts = [f\"{question} {candidate}\" for candidate in answers]\n",
    "  with torch.no_grad():\n",
    "    image_features = model.encode_image(clip_img)\n",
    "    qa_features = model.encode_text(clip.tokenize(input_texts).to(device))\n",
    "    similarity = (100.0 * image_features @ qa_features.T)\n",
    "\n",
    "  best_index = similarity.squeeze().argmax().item()\n",
    "  best_answer = answers[best_index]\n",
    "\n",
    "  print(f\"{similarity.squeeze()}\\n{question}\\n{best_answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
